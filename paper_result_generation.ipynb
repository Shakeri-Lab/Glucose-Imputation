{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea726146-6b10-4233-9db6-1a0874d5769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "BASE_PATH = \"New_DAY_NIGHT\"\n",
    "DATASET = \"simulate\"\n",
    "RATIO = \"3\"\n",
    "MODELS = [\"Lerp\", \"SAITS\", \"SCINet\", \"FreTS\"]  # Updated with your actual models\n",
    "SCENARIOS = [\"B\"]\n",
    "\n",
    "# Professional color scheme\n",
    "COLOR_MAP = {\n",
    "    \"Lerp\": \"#9B59B6\",      # Purple\n",
    "    \"SAITS\": \"#E74C3C\",     # Red\n",
    "    \"SCINet\": \"#F39C12\",    # Orange\n",
    "    \"FreTS\": \"#3498DB\",     # Blue\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# Data Loading\n",
    "# ============================================================================\n",
    "def load_scenario_data(base_path, dataset, model, scenario, ratio):\n",
    "    \"\"\"Load imputation results for a specific scenario and model.\"\"\"\n",
    "    filepath = os.path.join(\n",
    "        base_path, dataset, \"Mixed\", model, \n",
    "        f\"{scenario}_{ratio}_result_prediction.npy\"\n",
    "    )\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"⚠️  File not found: {filepath}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        data = np.load(filepath)\n",
    "        ground_truth = data[:, :, 0]\n",
    "        imputed = data[:, :, 1]\n",
    "        mask = data[:, :, 2]\n",
    "        \n",
    "        # Extract only masked values\n",
    "        is_masked = mask == 1\n",
    "        gt_masked = ground_truth[is_masked]\n",
    "        imp_masked = imputed[is_masked]\n",
    "        \n",
    "        print(f\"✓ Loaded {model}: {len(gt_masked)} imputed points\")\n",
    "        return gt_masked, imp_masked\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading {filepath}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ============================================================================\n",
    "# Plotting\n",
    "# ============================================================================\n",
    "def plot_scenario_calibration_separate():\n",
    "    \"\"\"Create separate calibration plots for each model in one row.\"\"\"\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.size'] = 11\n",
    "    \n",
    "    n_models = len(MODELS)\n",
    "    fig, axes = plt.subplots(\n",
    "        1, n_models,\n",
    "        figsize=(5 * n_models, 5),\n",
    "        sharey=True\n",
    "    )\n",
    "    \n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    scenario = SCENARIOS[0]  # Using first scenario\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Scenario {scenario} - Separate Model Comparison\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Store ground truth for comparison (load once)\n",
    "    gt_reference = None\n",
    "    \n",
    "    for idx, model in enumerate(MODELS):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Load data for this model\n",
    "        gt_values, imp_values = load_scenario_data(\n",
    "            BASE_PATH, DATASET, model, scenario, RATIO\n",
    "        )\n",
    "        \n",
    "        if gt_values is None:\n",
    "            ax.text(0.5, 0.5, f\"No data for {model}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "        \n",
    "        # Store first valid ground truth\n",
    "        if gt_reference is None:\n",
    "            gt_reference = gt_values\n",
    "        \n",
    "        # Calculate statistics\n",
    "        gt_mean = np.mean(gt_values)\n",
    "        gt_std = np.std(gt_values)\n",
    "        imp_mean = np.mean(imp_values)\n",
    "        imp_std = np.std(imp_values)\n",
    "        mae = np.mean(np.abs(imp_values - gt_values))\n",
    "        bias = imp_mean - gt_mean\n",
    "        \n",
    "        # Plot Ground Truth\n",
    "        sns.kdeplot(\n",
    "            gt_values, \n",
    "            ax=ax, \n",
    "            color=\"black\", \n",
    "            linestyle=\"--\", \n",
    "            linewidth=3, \n",
    "            label=\"Ground Truth\", \n",
    "            zorder=10,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Plot Model Distribution\n",
    "        model_color = COLOR_MAP.get(model, \"#34495E\")\n",
    "        sns.kdeplot(\n",
    "            imp_values, \n",
    "            ax=ax, \n",
    "            color=model_color, \n",
    "            fill=True,\n",
    "            alpha=0.3,\n",
    "            linewidth=2.5, \n",
    "            label=model\n",
    "        )\n",
    "        \n",
    "        # Add vertical lines for means\n",
    "        ax.axvline(\n",
    "            gt_mean, \n",
    "            color=\"black\", \n",
    "            linestyle=\"-\", \n",
    "            linewidth=2,\n",
    "            alpha=0.6,\n",
    "            label=f\"GT Mean: {gt_mean:.1f}\"\n",
    "        )\n",
    "        \n",
    "        ax.axvline(\n",
    "            imp_mean, \n",
    "            color=model_color, \n",
    "            linestyle=\":\", \n",
    "            linewidth=2.5,\n",
    "            alpha=0.8,\n",
    "            label=f\"{model} Mean: {imp_mean:.1f}\"\n",
    "        )\n",
    "        \n",
    "        # Add text box with statistics\n",
    "        stats_text = (\n",
    "            f\"MAE: {mae:.2f}\\n\"\n",
    "            f\"Bias: {bias:+.2f}\\n\"\n",
    "            f\"GT σ: {gt_std:.2f}\\n\"\n",
    "            f\"{model} σ: {imp_std:.2f}\"\n",
    "        )\n",
    "        \n",
    "        ax.text(\n",
    "            0.98, 0.97, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=9,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        )\n",
    "        \n",
    "        # Format subplot\n",
    "        ax.set_title(\n",
    "            f\"{model}\",\n",
    "            fontsize=14, \n",
    "            fontweight='bold',\n",
    "            pad=15,\n",
    "            color=model_color\n",
    "        )\n",
    "        ax.set_xlabel(\"Glucose Value (mg/dL)\", fontsize=12, fontweight='bold')\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(\"Probability Density\", fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Legend\n",
    "        legend = ax.legend(\n",
    "            loc='upper left',\n",
    "            frameon=True,\n",
    "            fancybox=True,\n",
    "            shadow=True,\n",
    "            fontsize=9\n",
    "        )\n",
    "        \n",
    "        # Grid styling\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        \n",
    "        # Spine styling\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(1.5)\n",
    "            spine.set_color(model_color)\n",
    "            spine.set_alpha(0.6)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"\\n{model:12s}\")\n",
    "        print(f\"  MAE:  {mae:7.2f} mg/dL\")\n",
    "        print(f\"  Bias: {bias:+7.2f} mg/dL\")\n",
    "        print(f\"  GT σ: {gt_std:7.2f} | {model} σ: {imp_std:7.2f}\")\n",
    "    \n",
    "    # Add main title\n",
    "    fig.suptitle(\n",
    "        # f\"Distribution Calibration Analysis - Scenario {scenario}\",\n",
    "        f\"Distribution Calibration Analysis - Scenario {scenario} (Peaks:{str(RATIO)})\",\n",
    "        fontsize=16,\n",
    "        fontweight='bold',\n",
    "        y=1.02\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save option\n",
    "    output_path = os.path.join(BASE_PATH, f\"calibration_separate_ratio_{scenario}_{RATIO}.png\")\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"\\n✓ Plot saved to: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# Main\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    plot_scenario_calibration_separate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6875464-8b84-436c-8890-8e803b7d480b",
   "metadata": {},
   "source": [
    "# Plot Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a740cc-20a8-4c04-9561-ce177d13f475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imputation Comparison Plotter\n",
    "Visualises ground truth vs. model imputations across masked (gap) regions.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "BASELINES = {\"Mean\", \"Median\", \"LOCF\", \"Lerp\"}\n",
    "\n",
    "COLOR_MAP = {\n",
    "    \"Ground Truth\": \"#000000\",  # Black (colorblind-safe)\n",
    "    # Baselines (colorblind-safe palette)\n",
    "    \"Mean\":      \"#7A7A7A\",\n",
    "    \"Median\":    \"#B3B3B3\",\n",
    "    \"LOCF\":      \"#1F1F1F\",\n",
    "    \"Lerp\":      \"#DE8F05\",     # Orange (colorblind-safe)\n",
    "    # Deep-learning models (colorblind-safe palette)\n",
    "    \"SAITS\":     \"#0173B2\",     # Blue (colorblind-safe)\n",
    "    \"FreTS\":     \"#1976D2\",\n",
    "    \"SCINet\":    \"#029E73\",     # Green (colorblind-safe)\n",
    "    \"TimeMixer\": \"#388E3C\",\n",
    "    \"TSLANet\":   \"#5D4037\",\n",
    "    \"TEFN\":      \"#00796B\",\n",
    "    \"TOTEM\":     \"#C2185B\",\n",
    "    \"GPT4TS\":    \"#FBC02D\",\n",
    "}\n",
    "\n",
    "\n",
    "# ──────────────────────────── Helpers ──────────────────────────────────\n",
    "\n",
    "def build_file_path(base_path: str, dataset: str, model: str,\n",
    "                    scenario: str, ratio: str) -> str:\n",
    "    \"\"\"Build the .npy path for a given dataset / model / scenario / ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : str\n",
    "        One of ``\"simulate\"``, ``\"pedap\"``, or ``\"none_pedap\"``.\n",
    "    \"\"\"\n",
    "    return os.path.join(base_path, dataset, \"Mixed\", model,\n",
    "                        f\"{scenario}_{ratio}_result_prediction.npy\")\n",
    "\n",
    "\n",
    "def load_sample(file_path: str, sample_idx: int) -> Tuple[np.ndarray, ...]:\n",
    "    \"\"\"Return (ground_truth, imputation, mask) for a single sample.\"\"\"\n",
    "    data = np.load(file_path)\n",
    "    return (\n",
    "        data[sample_idx, :, 0],\n",
    "        data[sample_idx, :, 1],\n",
    "        data[sample_idx, :, 2],\n",
    "    )\n",
    "\n",
    "\n",
    "def find_mask_segments(mask: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Detect contiguous masked regions as (start, end) pairs.\"\"\"\n",
    "    bounded = np.concatenate(([0], mask, [0]))\n",
    "    diffs = np.diff(bounded)\n",
    "    starts = np.where(diffs == 1)[0]\n",
    "    ends = np.where(diffs == -1)[0]\n",
    "    return list(zip(starts, ends))\n",
    "\n",
    "\n",
    "def get_style(model: str, idx: int, fallback_colors: np.ndarray):\n",
    "    \"\"\"Return (color, linestyle, linewidth) for a given model.\"\"\"\n",
    "    color = COLOR_MAP.get(model, fallback_colors[idx])\n",
    "    is_baseline = model in BASELINES\n",
    "    ls = \"--\" if is_baseline else \"-\"\n",
    "    lw = 1.5  # All model lines are 1.5pt\n",
    "    return color, ls, lw\n",
    "\n",
    "\n",
    "# ──────────────────────────── Plotting ─────────────────────────────────\n",
    "\n",
    "def plot_ground_truth(ax: plt.Axes, gt: np.ndarray,\n",
    "                      segments: List[Tuple[int, int]]) -> None:\n",
    "    \"\"\"Plot the ground-truth signal and shade each masked region.\"\"\"\n",
    "    ax.plot(gt, color=\"black\", lw=2.0, zorder=100, label=\"Ground Truth\")\n",
    "    for idx, (start, end) in enumerate(segments):\n",
    "        label = \"Masked Region\" if idx == 0 else None\n",
    "        ax.axvspan(start, end, color=\"#fff3cd\", alpha=0.5, label=label)\n",
    "\n",
    "\n",
    "def plot_meal_indicators(ax: plt.Axes,\n",
    "                         segments: List[Tuple[int, int]]) -> None:\n",
    "    \"\"\"Draw a vertical dashed line at each mask-segment start (Scenario B only).\"\"\"\n",
    "    for idx, (start, _end) in enumerate(segments):\n",
    "        ax.axvline(start, color=\"k\", linestyle=\":\", linewidth=2.0,\n",
    "                   alpha=0.9, zorder=200)\n",
    "\n",
    "\n",
    "def plot_imputation(ax: plt.Axes, imp: np.ndarray,\n",
    "                    segments: List[Tuple[int, int]], total_len: int,\n",
    "                    model: str, color, ls: str, lw: float) -> None:\n",
    "    \"\"\"Plot imputed values only inside (and one step beyond) each gap.\"\"\"\n",
    "    for j, (start, end) in enumerate(segments):\n",
    "        p_start = max(0, start - 1)\n",
    "        p_end = min(total_len, end + 1)\n",
    "        x = np.arange(p_start, p_end)\n",
    "        label = model if j == 0 else None\n",
    "        ax.plot(x, imp[p_start:p_end], color=color, ls=ls, lw=lw,\n",
    "                alpha=0.8, label=label)\n",
    "\n",
    "\n",
    "def style_axes(ax: plt.Axes, scenario: str, dataset: str,\n",
    "               total_len: int) -> None:\n",
    "\n",
    "    ax.set_xlabel(\"Time Steps (Whole Day)\", fontsize=14)\n",
    "    ax.set_ylabel(\"Glucose (mg/dL)\", fontsize=14)\n",
    "    ax.set_xlim(0, total_len)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\",\n",
    "              title=\"Models\", frameon=False, fontsize=14)\n",
    "\n",
    "\n",
    "# ──────────────────────────── Main ─────────────────────────────────────\n",
    "\n",
    "def plot_impute(cfg: dict, model_list: List[str]) -> None:\n",
    "    \"\"\"Generate the imputation comparison plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : dict\n",
    "        Must contain the keys ``base_path``, ``dataset``, ``scenario``,\n",
    "        ``ratio``, ``sample_idx``, ``total_len``, and ``fig_size``.\n",
    "        Optionally includes ``save_path`` to persist the figure to disk.\n",
    "    model_list : list[str]\n",
    "        Ordered list of model names to plot.\n",
    "    \"\"\"\n",
    "    fallback_colors = plt.cm.tab20(np.linspace(0, 1, len(model_list)))\n",
    "    fig, ax = plt.subplots(figsize=cfg[\"fig_size\"])\n",
    "\n",
    "    gt_plotted = False\n",
    "    mask_segments: List[Tuple[int, int]] = []\n",
    "\n",
    "    for i, model in enumerate(model_list):\n",
    "        fpath = build_file_path(\n",
    "            cfg[\"base_path\"], cfg[\"dataset\"],\n",
    "            model, cfg[\"scenario\"], cfg[\"ratio\"],\n",
    "        )\n",
    "        if not os.path.exists(fpath):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            gt, imp, mask = load_sample(fpath, cfg[\"sample_idx\"])\n",
    "            color, ls, lw = get_style(model, i, fallback_colors)\n",
    "\n",
    "            if not gt_plotted:\n",
    "                mask_segments = find_mask_segments(mask)\n",
    "                plot_ground_truth(ax, gt, mask_segments)\n",
    "                if cfg[\"scenario\"] == \"B\":\n",
    "                    plot_meal_indicators(ax, mask_segments)\n",
    "                gt_plotted = True\n",
    "\n",
    "            plot_imputation(ax, imp, mask_segments, cfg[\"total_len\"],\n",
    "                            model, color, ls, lw)\n",
    "\n",
    "        except Exception as exc:\n",
    "            print(f\"Error loading {model}: {exc}\")\n",
    "\n",
    "    style_axes(ax, cfg[\"scenario\"], cfg[\"dataset\"], cfg[\"total_len\"])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if \"save_path\" in cfg:\n",
    "        os.makedirs(cfg[\"save_path\"], exist_ok=True)\n",
    "        fname = (f\"{cfg['dataset']}_{cfg['scenario']}-{cfg['ratio']}-\"\n",
    "                 f\"{cfg['sample_idx']}.pdf\")\n",
    "        fig.savefig(os.path.join(cfg[\"save_path\"], fname),\n",
    "                    dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13f1cd-9123-445a-b831-62ba7ff36ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────── Entry Point ──────────────────────────────\n",
    "\n",
    "CONFIG = {\n",
    "    \"base_path\":  \"New_DAY_NIGHT/\",\n",
    "    \"dataset\":    'simulate',      # \"simulate\" | \"pedap\" | \"none_pedap\"\n",
    "    \n",
    "    \"scenario\":   \"B\",\n",
    "    \"ratio\":      \"1\",\n",
    "    \n",
    "    \"sample_idx\": 594,\n",
    "    \n",
    "    \"total_len\":  288,\n",
    "    \"fig_size\":   (14, 7),\n",
    "    # \"save_path\": \"Scenario_Plots/New_Day_Night/pdf\",\n",
    "}\n",
    "\n",
    "MODEL_LIST = [\"Lerp\", \"SAITS\", \"SCINet\"]\n",
    "\n",
    "plot_impute(CONFIG, MODEL_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d06a58-7f26-4360-a5f6-72fa9c46dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('./DAY_NIGHT/simulate/Mixed/Lerp/', \"C__result_prediction.npy\")\n",
    "for sample_idx in range(30000):\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    gt   = data[sample_idx, :, 0]\n",
    "    imp  = data[sample_idx, :, 1]\n",
    "    mask = data[sample_idx, :, 2]\n",
    "    if sum(mask) > 1:\n",
    "        print(sample_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534763b-5b77-4806-8aae-4309fa44f2ff",
   "metadata": {},
   "source": [
    "# Generate Table in Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8b3b6-fd71-46b9-b1cd-c2156be3e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# =============== USER SETTINGS ===============\n",
    "target_scenarios = ['C']          # <- ['A'] or ['B'] or ['C'] or ['A','B','C']\n",
    "exclude = ['MSE', 'MAE']\n",
    "\n",
    "file_patterns = {\n",
    "    # \"pedap\": \"DAY_NIGHT/pedap/aggregated_results_*.csv\",\n",
    "    \"simulate\": \"New_DAY_NIGHT/simulate/aggregated_results_*.csv\",\n",
    "    # \"none_pedap\": \"DAY_NIGHT/none_pedap/aggregated_results_*.csv\",\n",
    "}\n",
    "\n",
    "# datasets = [\"pedap\", \"none_pedap\", \"simulate\"]\n",
    "# ds_titles = {\"pedap\": \"Processed_PEDAP\", \"simulate\": \"Simulation\", \"none_pedap\": \"Raw_PEDAP\"}\n",
    "datasets = [\"simulate\"]\n",
    "ds_titles = {\"pedap\": \"Processed_PEDAP\", \"simulate\": \"Simulation\", \"none_pedap\": \"Raw_PEDAP\"}\n",
    "\n",
    "# Model order in the table (top-to-bottom within each Ratio)\n",
    "MODEL_ORDER = [\n",
    "    \"FreTS\",\n",
    "    \"SCINet\",\n",
    "    \"TimeMixer\",\n",
    "    \"TSLANet\",\n",
    "    \"TEFN\",\n",
    "    \"TOTEM\",\n",
    "    \"GPT4TS\",\n",
    "    \"SAITS\",\n",
    "    \"Mean\",\n",
    "    \"Median\",\n",
    "    \"LOCF\",\n",
    "    \"Lerp\",\n",
    "]\n",
    "# ============================================\n",
    "\n",
    "all_data = []\n",
    "\n",
    "def tex_escape(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return text.replace('_', r'\\_').replace('%', r'\\%').replace('&', r'\\&')\n",
    "\n",
    "# --------- Read datasets ----------\n",
    "for dataset_name, file_pattern in file_patterns.items():\n",
    "    for f in glob.glob(file_pattern):\n",
    "        match = re.search(r\"results_([A-Z])_([\\d.]+)\\.csv\", f)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        s, r = match.group(1), match.group(2)\n",
    "        if s not in target_scenarios:\n",
    "            continue\n",
    "\n",
    "        tmp = pd.read_csv(f)\n",
    "        tmp = tmp.drop(columns=[c for c in exclude if c in tmp.columns])\n",
    "        tmp[\"Scenario\"] = s\n",
    "        tmp[\"Ratio\"] = r\n",
    "        tmp[\"Dataset\"] = dataset_name\n",
    "        all_data.append(tmp)\n",
    "\n",
    "if not all_data:\n",
    "    print(\"% No files found for the requested scenarios.\")\n",
    "else:\n",
    "    df = pd.concat(all_data).reset_index(drop=True)\n",
    "\n",
    "    # Identify columns: [Model, metric1, metric2, ...]\n",
    "    cols_wo_meta = [c for c in df.columns if c not in [\"Scenario\", \"Ratio\", \"Dataset\"]]\n",
    "    model_col_name = cols_wo_meta[0]\n",
    "    metric_cols = cols_wo_meta[1:]\n",
    "\n",
    "    # Make metrics numeric\n",
    "    for col in metric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # ========= One table per scenario =========\n",
    "    for scenario in sorted(df[\"Scenario\"].unique()):\n",
    "        s_df = df[df[\"Scenario\"] == scenario].copy()\n",
    "        if s_df.empty:\n",
    "            continue\n",
    "\n",
    "        # pivot => index (Ratio, Model), columns (Dataset, Metric)\n",
    "        pivot = s_df.pivot_table(\n",
    "            index=[\"Ratio\", model_col_name],\n",
    "            columns=\"Dataset\",\n",
    "            values=metric_cols,\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "\n",
    "        # ensure columns are (Dataset, Metric) and in consistent order\n",
    "        pivot = pivot.reorder_levels([1, 0], axis=1)  # (Dataset, Metric)\n",
    "        pivot = pivot.reindex(columns=pd.MultiIndex.from_product([datasets, metric_cols]), copy=False)\n",
    "\n",
    "        # --- Ranking per ratio, per dataset, per metric ---\n",
    "        best, second = {}, {}\n",
    "        ratios = sorted(pivot.index.get_level_values(0).unique(), key=float)\n",
    "\n",
    "        for ratio in ratios:\n",
    "            for ds in datasets:\n",
    "                for m in metric_cols:\n",
    "                    col = (ds, m)\n",
    "                    series = pivot.loc[ratio, col]  # indexed by model\n",
    "\n",
    "                    valid = series.dropna()\n",
    "                    if valid.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Bias: closest to 0 best; others: lowest best\n",
    "                    if \"bias\" in m.lower():\n",
    "                        order = valid.abs().sort_values().index.tolist()\n",
    "                    else:\n",
    "                        order = valid.sort_values().index.tolist()\n",
    "\n",
    "                    best[(ratio, ds, m)] = order[0] if len(order) >= 1 else None\n",
    "                    second[(ratio, ds, m)] = order[1] if len(order) >= 2 else None\n",
    "\n",
    "        # --- LaTeX ---\n",
    "        col_setup = \"c l \" + \" \".join([\"c\" * len(metric_cols) for _ in datasets])\n",
    "\n",
    "        latex = [\n",
    "            \"\\\\begin{table}[t]\",\n",
    "            \"\\\\centering\",\n",
    "            f\"\\\\caption{{Performance Comparison (Scenario {scenario}). \"\n",
    "            \"\\\\textbf{Bold} is best, \\\\underline{underline} is 2nd best. \"\n",
    "            \"(Closest to 0 for Bias, Lowest for others)}}\",\n",
    "            f\"\\\\label{{tab:results_{scenario}_all_datasets}}\",\n",
    "            \"\\\\small\",\n",
    "            \"\\\\setlength{\\\\tabcolsep}{4pt}\",\n",
    "            f\"\\\\begin{{tabular}}{{{col_setup}}}\",\n",
    "            \"\\\\toprule\",\n",
    "        ]\n",
    "\n",
    "        # Header row: dataset blocks\n",
    "        header = \"\\\\textbf{Ratio} & \\\\textbf{Model}\"\n",
    "        for ds in datasets:\n",
    "            header += f\" & \\\\multicolumn{{{len(metric_cols)}}}{{c}}{{\\\\textbf{{{ds_titles.get(ds, ds)}}}}}\"\n",
    "        header += \" \\\\\\\\\"\n",
    "        latex.append(header)\n",
    "\n",
    "        # cmidrules for each dataset block\n",
    "        start_col = 3\n",
    "        cmid = []\n",
    "        for _ in datasets:\n",
    "            end_col = start_col + len(metric_cols) - 1\n",
    "            cmid.append(f\"\\\\cmidrule(lr){{{start_col}-{end_col}}}\")\n",
    "            start_col = end_col + 1\n",
    "        latex.append(\"\".join(cmid))\n",
    "\n",
    "        metric_hdr = \" & \".join([f\"\\\\textbf{{{tex_escape(m)}}}\" for m in metric_cols])\n",
    "        latex.append(\" &  & \" + \" & \".join([metric_hdr for _ in datasets]) + \" \\\\\\\\\")\n",
    "        latex.append(\"\\\\midrule\")\n",
    "\n",
    "        # sort rows by ratio numeric (models will be ordered separately per ratio)\n",
    "        pivot_sorted = pivot.reset_index()\n",
    "        pivot_sorted[\"Ratio_float\"] = pivot_sorted[\"Ratio\"].astype(float)\n",
    "        pivot_sorted = pivot_sorted.sort_values([\"Ratio_float\", model_col_name]).drop(columns=[\"Ratio_float\"])\n",
    "        pivot_sorted = pivot_sorted.set_index([\"Ratio\", model_col_name])\n",
    "\n",
    "        # --- Write rows grouped by Ratio (print ratio once + separator line) ---\n",
    "        ratios_in_table = sorted(pivot_sorted.index.get_level_values(0).unique(), key=float)\n",
    "\n",
    "        for ri, ratio in enumerate(ratios_in_table):\n",
    "            ratio_block = pivot_sorted.loc[ratio]  # index = model_col_name\n",
    "\n",
    "            # Enforce your chosen model order (unknown models go to bottom)\n",
    "            ratio_block = (\n",
    "                ratio_block\n",
    "                .reset_index()\n",
    "                .assign(**{\n",
    "                    model_col_name: lambda d: pd.Categorical(\n",
    "                        d[model_col_name].astype(str),\n",
    "                        categories=MODEL_ORDER,\n",
    "                        ordered=True\n",
    "                    )\n",
    "                })\n",
    "                .sort_values(model_col_name)\n",
    "                .set_index(model_col_name)\n",
    "            )\n",
    "\n",
    "            first_row = True\n",
    "            for model, row in ratio_block.iterrows():\n",
    "                model_str = str(model)\n",
    "                model_tex = tex_escape(model_str)\n",
    "\n",
    "                ratio_cell = ratio if first_row else \"\"\n",
    "                first_row = False\n",
    "\n",
    "                cells = [ratio_cell, model_tex]\n",
    "\n",
    "                for ds in datasets:\n",
    "                    for m in metric_cols:\n",
    "                        val = row[(ds, m)]\n",
    "                        if pd.isna(val):\n",
    "                            s_val = \"--\"\n",
    "                        else:\n",
    "                            s_val = f\"{val:.2f}\"\n",
    "                            if model_str == str(best.get((ratio, ds, m))):\n",
    "                                s_val = f\"\\\\textbf{{{s_val}}}\"\n",
    "                            elif model_str == str(second.get((ratio, ds, m))):\n",
    "                                s_val = f\"\\\\underline{{{s_val}}}\"\n",
    "                        cells.append(s_val)\n",
    "\n",
    "                latex.append(\" & \".join(cells) + \" \\\\\\\\\")\n",
    "\n",
    "            if ri < len(ratios_in_table) - 1:\n",
    "                latex.append(\"\\\\midrule\")\n",
    "\n",
    "        latex += [\n",
    "            \"\\\\bottomrule\",\n",
    "            \"\\\\end{tabular}\",\n",
    "            \"\\\\end{table}\",\n",
    "        ]\n",
    "\n",
    "        print(\"\\n\".join(latex))\n",
    "        print(\"\\n% ==========================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f40e54-1727-4408-b009-50f886cec74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Setup\n",
    "# ---------------------------------------------------------\n",
    "base_path = 'New_DAY_NIGHT/'\n",
    "model_list = [\"SAITS\", \"FreTS\", \"SCINet\", \"TimeMixer\", \"TSLANet\", \"TEFN\", \"TOTEM\", \"GPT4TS\", \"Lerp\", \"LOCF\", \"Median\", \"Mean\"]\n",
    "\n",
    "\n",
    "ratio, scenario, is_simulate = 0.3, 'A', True\n",
    "sub_folder = 'simulate' if is_simulate else 'none_pedap'\n",
    "result_name = f\"{scenario}_{ratio}_metrics.json\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "for model in model_list:\n",
    "    dir_path = os.path.join(base_path, sub_folder, 'Mixed', model)\n",
    "    result_path = os.path.join(dir_path, result_name)\n",
    "    try:\n",
    "        if os.path.exists(result_path):\n",
    "            # Load the JSON as a Series\n",
    "            s = pd.read_json(result_path, typ='series')            \n",
    "            df_temp = s.to_frame().T            \n",
    "            df_temp.insert(0, 'Model', model)\n",
    "            \n",
    "            all_results.append(df_temp)\n",
    "            print(f\"[OK] Merged results for: {model}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"[Missing] File not found: {result_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed on {model}: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    output_name = f\"aggregated_results_{scenario}_{ratio}.csv\"\n",
    "    output_path = os.path.join(base_path, sub_folder, output_name)\n",
    "    \n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Success! Saved to: {output_path}\")\n",
    "    print(final_df.head()) # Quick preview\n",
    "else:\n",
    "    print(\"No data was found. Check your file paths and model names.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
