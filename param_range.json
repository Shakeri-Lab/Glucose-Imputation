{
  "CSDI": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_layers": {"min": 2, "max": 6, "step": 2},
    "n_heads": {"min": 2, "max": 8, "step": 2},
    "n_channels": {"min": 32, "max": 128, "step": 32},
    "d_time_embedding": {"min": 32, "max": 128, "step": 32},
    "d_feature_embedding": {"min": 8, "max": 32, "step": 8},
    "d_diffusion_embedding": {"min": 64, "max": 256, "step": 64}
  },

  "FreTS": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "embed_size": {"min": 128, "max": 256, "step": 64},
    "hidden_size": {"min": 64, "max": 128, "step": 32},
    "channel_independence": false
  },

  "SAITS": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_layers": {"min": 2, "max": 4, "step": 1},
    "d_model": {"min": 64, "max": 256, "step": 64},
    "d_ffn": {"min": 256, "max": 512, "step": 128},
    "n_heads": {"min": 2, "max": 8, "step": 2},
    "dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "attn_dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "d_k": {"min": 32, "max": 128, "step": 32},
    "d_v": {"min": 32, "max": 128, "step": 32}
  },

  "SCINet": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "n_stacks": {"min": 1, "max": 3, "step": 1},
    "n_levels": {"min": 2, "max": 3, "step": 1},
    "n_groups": 1,
    "n_decoder_layers": {"min": 1, "max": 3, "step": 1},
    "d_hidden": {"min": 32, "max": 128, "step": 32}
  },

  "Transformer": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_layers": {"min": 2, "max": 4, "step": 1},
    "d_model": {"min": 64, "max": 256, "step": 64},
    "d_ffn": {"min": 256, "max": 512, "step": 128},
    "n_heads": {"min": 2, "max": 8, "step": 2},
    "dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "attn_dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "d_k": {"min": 32, "max": 128, "step": 32},
    "d_v": {"min": 32, "max": 128, "step": 32}
  },

  "TimeMixer": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_layers": {"min": 1, "max": 3, "step": 1},
    "d_model": {"min": 64, "max": 256, "step": 64},
    "d_ffn": {"min": 256, "max": 512, "step": 128},
    "top_k": {"min": 3, "max": 5, "step": 1},
    "dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "channel_independence": true,
    "decomp_method": "moving_avg",
    "moving_avg": 25,
    "downsampling_layers": {"min": 1, "max": 3, "step": 1},
    "downsampling_window": 2
  },

  "TimeMixerPP": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_layers": {"min": 1, "max": 3, "step": 1},
    "d_model": {"min": 64, "max": 256, "step": 64},
    "d_ffn": {"min": 256, "max": 512, "step": 128},
    "n_heads": {"min": 2, "max": 8, "step": 2},
    "top_k": {"min": 3, "max": 5, "step": 1},
    "dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "channel_independence": true,
    "channel_mixing": false,
    "n_kernels": {"min": 2, "max": 4, "step": 1},
    "downsampling_layers": {"min": 1, "max": 3, "step": 1},
    "downsampling_window": 2
  },

  "ModernTCN": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "patch_size": {"min": 4, "max": 16, "step": 4},
    "patch_stride": {"min": 4, "max": 16, "step": 4},
    "downsampling_ratio": 2,
    "ffn_ratio": {"min": 1, "max": 4, "step": 1},
    "num_blocks": [
      {"min": 1, "max": 3, "step": 1},
      {"min": 1, "max": 3, "step": 1},
      {"min": 1, "max": 3, "step": 1}
    ],
    "large_size": [
      {"min": 15, "max": 31, "step": 4},
      {"min": 15, "max": 31, "step": 4},
      {"min": 15, "max": 31, "step": 4}
    ],
    "small_size": [
      {"min": 3, "max": 13, "step": 4},
      {"min": 3, "max": 13, "step": 4},
      {"min": 3, "max": 13, "step": 4}
    ],
    "dims": [
      {"min": 64, "max": 256, "step": 64},
      {"min": 64, "max": 256, "step": 64},
      {"min": 64, "max": 256, "step": 64}
    ], 
    "small_kernel_merged": false,
    "backbone_dropout": 0.1,
    "head_dropout": 0.1,
    "individual": true
  },

  "TSLANet": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_layers": {"min": 2, "max": 4, "step": 1},
    "patch_size": {"min": 4, "max": 16, "step": 4},
    "d_embedding": {"min": 64, "max": 256, "step": 64},
    "mask_ratio": {"min": 0.2, "max": 0.6, "step": 0.1},
    "dropout": 0.15
  },

  "TEFN": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "n_fod": {"min": 1, "max": 4, "step": 1},
    "apply_nonstationary_norm": true
  },

  "TOTEM": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "d_block_hidden": {"min": 64, "max": 256, "step": 64},
    "n_residual_layers": {"min": 2, "max": 6, "step": 2},
    "d_residual_hidden": {"min": 32, "max": 128, "step": 32},
    "d_embedding": {"min": 64, "max": 256, "step": 64},
    "n_embeddings": 32,
    "commitment_cost": 0.25,
    "compression_factor": 4
  },

  "GPT4TS": {
    "n_steps": 288,
    "n_features": 4,
    "epochs": 100,
    "patience": 10,
    "batch_size": 32,
    "num_workers": 2,
    "lr": {"min": 1e-4, "max": 1e-3, "step": "log"},
    "patch_size": {"min": 4, "max": 16, "step": 4},
    "patch_stride": {"min": 4, "max": 16, "step": 4},
    "n_layers": {"min": 1, "max": 3, "step": 1},
    "d_ffn": {"min": 128, "max": 512, "step": 128},
    "dropout": {"min": 0.1, "max": 0.3, "step": 0.1},
    "train_gpt_mlp": false,
    "embed": "fixed",
    "freq": "h"
  }
}
